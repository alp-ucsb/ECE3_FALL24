{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab9_Solved.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FJmCCVjpadTy"},"source":["# ECE 3 - Lab 9"]},{"cell_type":"markdown","metadata":{"id":"elx4T-wCahcc"},"source":["# Least Squares Introduction\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cd0XNMs4SXRU"},"source":["$\\color{#EF5645}{\\text{Definition}}$: Given a $m \\times n$ matrix $A$ and $m$-vector $b$, the **Least Squares** problem is the problem of choosing an $n$-vector $x$ to minimize:\n","$$‖Ax − b‖^2.$$\n","\n","- If $\\hat x$ is a solution of the linear equation $Ax = b$, then $\\hat x$ is a solution of the least square problem. The converse is not true. (Explain Why)"]},{"cell_type":"markdown","metadata":{"id":"p66i3xe9HNHu"},"source":["## Exercise 1\n","Show $$\\hat x = (A^T A)^{-1} A^Tb = A^\\dagger b$$ is the unique solution to the least square problem."]},{"cell_type":"markdown","metadata":{"id":"XjjCqwg5CDIT"},"source":["## Solution\n","$||Ax - b||^2 = x^TA^TAx - b^TAx - x^TA^Tb + b^Tb$.\n","\n","Its derivative with respect to $x$ is $2x^TA^TA - 2b^TA$.\n","\n","Set the derivative to $0$ we get $x^TA^TA = b^TA$.\n","\n","Take the transpose of both sides of the equation: $A^T A x = A^T b$.\n","\n","$A^TA$ is invertible (explain why)\n","\n","Thus $\\hat x = (A^T A)^{-1} A^Tb$."]},{"cell_type":"markdown","metadata":{"id":"qQdMPmXeVdpH"},"source":["## Exercise 2\n","If $A$ has $QR$ factorization $A = QR$, show that $A\\hat{x} = QQ^Tb$."]},{"cell_type":"markdown","metadata":{"id":"uWnksfS6V54p"},"source":["## Solution\n","$A\\hat{x} = QR(R^TQ^TQR)^{-1}R^TQ^Tb = QRIR^TQ^Tb = QIQ^Tb = Q$"]},{"cell_type":"markdown","metadata":{"id":"-UERrqwIM26e"},"source":["# Least Square Data Fitting\n"]},{"cell_type":"markdown","metadata":{"id":"IfuZ9FTTNOo7"},"source":["Given\n","$$x^{(1)}, . . . , x^{(N)}, y^{(1)}, . . . , y^{(N)}$$\n","\n","We try to find the function $\\hat{f}$ that maps $x$ to $y$.\n","$$\\hat{f}(x) = \\theta_1 f_1(x) + ... + \\theta_p f_p(x)$$\n","\n","To measure how good the $\\hat{f}$ we found is, we use $\\bf{residual}/error$. The best $\\hat{f}$ is the one giving the smallest error.\n","$$r_i = y^{(i)} - \\hat{y}^{(i)}.$$\n","\n","The problem is called \"Least Square\" because we use the squared of the residual rather than the residual itself so that we do not worry about negative versus positive residual.\n","\n","Formulated as a least square problem:\n","\n","Define the $N \\times p$ matrix $A$ with elements $A_{ij} = f_j(x^{(i)})$, such that $\\hat y =A \\theta$. The least square data fitting problem amounts to choose $\\theta$ that minimizes:\n","$$||A\\theta - y||^2$$."]},{"cell_type":"markdown","metadata":{"id":"C3x6bnjWQIyc"},"source":["## Exercise 2\n","Given data points $(-0.5,6), (0,3), (1.1,0), (1.6,0),(2.5,3.2)$ and $\\hat{f} = \\theta_1x^2 + \\theta_2x + \\theta_3$. Use Python to find the optimal $\\theta$."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-J_mtO3WQoko","executionInfo":{"status":"ok","timestamp":1638317460461,"user_tz":480,"elapsed":7,"user":{"displayName":"Orestis Paraskevas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00734435821983708962"}},"outputId":"4f92cdef-62c1-4d34-9c05-807ea50f3bb4"},"source":["import numpy as np\n","y = np.array([[6],[3],[0],[0],[3.2]])\n","A = np.array([[(-0.5)**2, -0.5, 1],\n","              [0**2,        0,  1],\n","              [1.1**2,     1.1, 1],\n","              [1.6**2,     1.6, 1],\n","              [2.5**2,     2.5, 1]])\n","theta = np.linalg.inv(np.transpose(A)@A)@np.transpose(A)@y\n","theta"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.05490805],\n","       [-5.06380544],\n","       [ 2.97919598]])"]},"metadata":{},"execution_count":1}]}]}
